%\section{Introduction}

%Recent advances in tracking technology allows ecologists to collect an unprecedented amount of movement and kinematic data for a wide variety of animals \citep{Patterson:2017}. These data sets allow researchers to detect hunting behaviour \citep{Heerah:2017}, understand habitat selection \citep{Michelot:2019b}, and develop activity budgets \citep{Dot:2016} for these animals. Understanding an animal's movement and behaviour can assist in their conservation \citep{Sutherland:1998}. One of the most prevalent models used to describe animal movement is the hidden Markov model, or HMM \citep{McClintock:2020}.

Hidden Markov models (HMM) are common statistical models used to describe sequential data. They are widely used to model time series data in a variety of fields such as speech recognition \citep{Gales:2008}, geology \citep{Bebbington:2007}, neuroscience \citep{Kottaram:2019}, finance \citep{Mamon:2007}, and ecology \citep{McClintock:2020}. Such models are used to identify a latent process of interest (e.g. a spoken phrase or an animal's behavioural state), from an observed time series (e.g. raw audio or accelerometer data). Hidden Markov models can be used in both supervised and unsupervised settings.

%Observations from an HMM are generated from a distribution which depends upon the state of an unobserved (or ``hidden") Markov chain. 
The parameters of an HMM can be estimated by maximizing the likelihood function with respect to those parameters. The likelihood is usually maximized using either gradient-based numerical maximization or the Baum-Welch algorithm \citep{Baum:1970}.
%On the other hand, Bayesian inference usually involves sampling parameters from a posterior distribution using MCMC techniques, although recent work has approximated the posterior distribution using variational inference \citep{Foti:2014}.
%First, the likelihood can be maximized directly using standard numerical maximization techniques such as gradient descent. Alternatively, practitioners can use the \textit{Baum-Welch} algorithm , which is a specific instance of the EM algorithm adapted for HMMs. 
The Baum-Welch algorithm has several appealing theoretical guarantees compared to gradient descent, but it is less flexible and non-trivial to adapt to more complicated models. In addition, it requires solving a optimization problem at each step, even when the optimization problem does not have a closed-form solution. %Finally, the Baum-Welch algorithm converges linearly to a local maximum of the likelihood function, while second-order gradient descent methods \citep{Khreich:2012} can converge quadratically. Ultimately, the decision between using the Baum-Welch algorithm versus gradient descent depends upon the researcher.

%Likelihood maximization techniques return point estimates of parameter values and rely on the Fisher information to estimate standard errors. This approach fails to capture any multi-modality in the sampling distribution of the parameter estimates. In addition, likelihood maximization tends to estimate the probability of each hidden state $X_t$ conditioned on the parameter estimates $\hat \theta$, rather than estimating the parameters and hidden states jointly. Bayesian models solve both of these issues: they define a posterior distribution that models uncertainty in parameter estimates and jointly estimate the hidden states $X_t$ along with the parameters $\theta$. 

%Unfortunately, most Bayesian models require sampling from a posterior distribution using MCMC techniques that are seen as more computationally expensive compared to likelihood maximization. However, the advent of Hamiltonian Monte Carlo \citep{Neal:2012}, the no-U-turn sampler \citep{Homan:2014}, non-reversible parallel tempering \citep{Syed:2019,Sacchi:2021}, and their implementation in statistical software such as \textit{stan} \citep{Stan:2021} and \textit{blang} \citep{Bouchard:2021} has considerably reduced the computational barrier of MCMC.

One serious concern for both the Baum-Welch algorithm and direct likelihood maximization is that each parameter update step involves iterating though the full set of observations to calculate the likelihood or its gradient. 
In particular, for a data set of length $T$, both have a time complexity of $\mathcal{O}(T)$.
This linear time complexity is relatively efficient, but time-series data sets are collected at high-frequencies and are becoming increasingly large \citep{Patterson:2017,Li:2020}. As a result, they require increasingly complex HMMs to model effectively \citep{Adam:2019,Sidrow:2021}. In addition, many model validation techniques such as cross-validation require repeated parameter estimation which can be computationally prohibitive even for relatively simple HMMs \citep{Pohle:2017}.

%To speed up likelihood evaluation, \citet{Nielsen:2011} evaluate the matrix multiplications from Equation (\ref{eqn:HMM_like}) in parallel. However, this algorithm actually \textit{increases} the time complexity of the algorithm to $\mathcal{O}(N^3 T)$ and can be too slow for large $N$ or when parallel computational power is limited.

Many inference techniques for \textit{independent} data do not require iterating through the entire data set to update a model's parameters. We henceforth refer to these techniques as sub-linear methods because the time complexity of one parameter update is faster than linear in $T$. 
%but most %sub-linear inference methods 
%rely on independence assumptions that are violated in applications involving sequential data. 
% require dividing the data set into subsets that are assumed to be independent of one another. Unfortunately, HMMs explicitly model serial dependence between observations, so it is difficult to divide a data set into independent subsets. 
% I will nonetheless review a selection of sub-linear inference methods for direct likelihood maximization, expectation maximization, and Bayesian inference to provide background and inspiration for my proposed method.
%
For example, stochastic gradient descent relies on an unbiased estimate of the full gradient by evaluating the gradient of the likelihood over a random subset of the data \citep{Robbins:1951}. It is ubiquitous in the machine learning literature \citep{Johnson:2013, Defazio:2014, Kingma:2014}. %However, most theoretical guarantees rely on the assumption that all observations are independent of one another. 
%Stochastic gradient algorithms work by randomly sampling a sub-set of data, evaluating the gradient over that sub-set's likelihood, and taking a gradient step to update the parameters of the model. Stochastic gradient descent is known to converge to a local minimum of the negative log-likelihood under mild regularity conditions if each randomly sampled sub-set is independent under the generating model \citep{Robbins:1951}. %However, this independence assumption is violated for time-series data since observations are correlated in time.
%
Similarly, the \textit{incremental} EM algorithm is a generalization of the EM algorithm often used to fit mixture model which involves updating only a subset of hidden variables at each step \citep{Neal:1998, Thiesson:2001, Karimi:2019}. %Convergence properties of various stochastic gradient descent techniques and stochastic-EM algorithms have been derived by \citet{Chen:2018} and \citet{Karimi:2019}, respectively.
%
%For Bayesian inference, stochastic gradient descent MCMC is a sub-linear sampling technique \citep{Ma:2015} that has been implemented in R \citep{Baker:2019}. \citet{Nemeth:2021} show that stochastic gradient descent can out-perform Hamiltonian Monte Carlo in some settings. In addition, stochastic variational inference (SVI) is a variational inference technique that updates an approximate posterior distribution without iterating thought the entire data  \citep{Hoffman:2013}.
%
However, these methods rely on the assumption that the data set can be easily divided into independent subsets. This assumption is violated for HMMs because the underlying data set exhibits sequential dependence. 

Some work has been done to apply sub-linear inference methods to HMMs.
%In the context of correlated data and HMMs, however, many of these methods either break down or require significant adjustments. In the case of direct likelihood maximization, %\citet{Saaudi:2019} implement stochastic gradient descent for HMMs, but their gradient estimates are biased and they do not provide any theoretical guarantees regarding approximation error or convergence properties. 
\citet{Gotoh:1998} divides the observation sequence into sub-sequences
%, assumes that each sub-sequence is independent, 
and uses the incremental EM algorithm on the resulting collection of sub-sequences. This approach speeds up inference, but it assumes that sub-sequences of data are independent of one another, which is not the case when independent replicates of data are not available. \citet{Ye:2017} define a sufficiently large ``buffer" between subsets of data so they are approximately independent of one another. %The authors then use these approximately independent subsets of data to perform stochastic gradient descent for HMM parameter inference. 
However, the size of the buffer can be difficult to calculate. %since it depends upon the Lyapunov exponent of a dynamical system defined by the probability transition matrix of an HMM. 
More examples of sub-linear inference techniques are given by \citet{Khreich:2012}, which reviews on-line and incremental methods for HMM inference. However, most of these methods assume that the M-step of the EM algorithm is tractable (see section 3.2.1 of \citet{Khreich:2012}) or that the emissions of the HMM are discrete \citep{Baldi:1993}. 

One method that is particularly aligned with ours is \citet{Zhu:2017}, which implements variance-reduced stochastic optimization to perform the M-step of the EM algorithm on high-dimensional latent-variable models. That method obtains a sub-linear computational complexity in $T$ and attains a linear convergence rate. However, that paper focuses primarily on mixture models rather than HMMs, and it does not combine the variance-reduced stochastic M-step with a partial E-step, which is an extension that we implement here. Further, the theory from that paper relies on an assumption of independence between observations.

In this paper, we introduce a new inference method for HMMs based on variance-reduced stochastic optimization. This inference method updates the HMM parameters without iterating through the entire data set. Critically, it does not require a closed-form solution for its M-step, it does not require any buffer tuning, and it does not introduce error into the HMM likelihood. In section 2, we formally define HMMs, review standard inference techniques for HMMs, and describe stochastic optimization algorithms. In section 3, we introduce our algorithm and prove that it converges to a local maximum of the likelihood (under standard regularity assumptions). We then propose a natural extension to improve its empirical performance on large data sets. In section 4, we describe several practical considerations regarding the algorithm's implementation. In section 5, we describe several experiments which compare our algorithm with standard optimization techniques and demonstrate its advantages on large data sets and complicated models. In section 6, we discuss our results and conclusions.
%\citep{Cappe:1998} argue for a quasi-Newton algorithm for quadratic convergence, but our simulation studies show that an out-of-the-box implementation of BFGS (a quasi-Newton optimization algorithm) for HMMs performs very poorly if the original parameter estimates are not close to the optimum parameters. 
%\citet{Hsu:2012} introduce spectral methods for estimating HMMs, but this method avoids inferring the probability transition matrix and hidden states directly, even though these hidden states may be of interest to practitioners.

%In a Bayesian setting, \citet{Foti:2014} implements stochastic variational inference for HMMs while \citet{Ma:2017} develops stochastic gradient MCMC for HMM. Both of these methods rely on the same basic structure as \citet{Ye:2017} and therefore suffer from the same issues. Namely, both methods have approximation error and requires that users calculate a sufficiently large subset size at each step during parameter inference.

%In summary, it is difficult to account for the dependence structure of an HMM when developing efficient inference methods. As such, I will develop methods to split a data set generated from a PHMM into independent segments using the conditional independence property of PHMMs. Then, methods that require independent data such as stochastic gradient descent, incremental EM, SGMCMC, and variational inference can be used in a plug-and-play manner. I will also generalize these methods to perform sub-linear parameter updates for traditional HMMs (in addition to PHMMs).

%Independence between HMM sub-sequences has several applications beyond stochastic gradient and EM methods. These include, but are not limited to, tempering by subsampling \citep{vandeMeent:2014}, annealing by increasing resampling (AIR) \citep{Higuchi:2020}, and Bayesian or Hilbert coreset construction \citep{Campbell:2019}. It is my goal to perform short case and/or simulation studies to implement these inference methods and compare them with others mentioned earlier in this proposal. Luckily, many theoretical guarantees have already been derived in the references above, so by introducing independence into the HMM model, I get these theoretical guarantees for free.

%This chapter is organized as follows: First, I set up notation and write the likelihood of a PHMM in terms of subsets of observations that are \textit{independent} conditioned on the set of labels $\{L_t\}_{t=1}^T = \{\ell_t\}_{t=1}^T$. Next, I generalize this technique so that it can be applied to a standard HMM (i.e., when no labels are known). After that, I introduce a memoization algorithm for HMM inference that uses stored likelihood estimates and avoids the need to condition on labels at all. Finally, I propose experiments and metrics that I will use to evaluate and compare these methods.