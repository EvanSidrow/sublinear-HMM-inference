%\section{Practical Considerations}

Algorithms (\ref{alg:EM-SO}) and (\ref{alg:P-EM-SO}) outline methods to perform the Baum-Welch algorithm with a stochastic E and M step. This section outlines implementation details that improve the practical performance of each algorithm. In particular, this section outlines methods to select an appropriate step size which can drastically affect the practical performance of the algorithm.

\subsection{Line-search for step size selection}
\label{subsec:est_L}

One major drawback of stochastic optimization algorithms is that the step size can greatly affect practical performance. %\citet{Schmidt:2017} suggest using step sizes of $\lambda_F = 1/(16L_F)$ and $\lambda_G = 1/(16L_G)$ for theoretical guarantees within the SAG algorithm, where $L_F$ and $L_G$ are defined in Theorem 1. Similarly, 
\citet{Defazio:2014} suggest step sizes of $\lambda_F = 1/(3L_F)$ and $\lambda_G = 1/(3L_G)$ for SAGA, where $L_F$ and $L_G$ are the Lipschitz constants defined in Theorem 1. However, these Lipschitz constants are rarely known in practice. Therefore, following \citet{Schmidt:2017}, we initialize estimates of the Lipschitz constants, $\hat L_F$ and $\hat L_G$, and update them if either of the following inequalities do not hold at an iteration of the optimization algorithm:
%
\begin{gather}
    F^{(k,\ell,m)}_{t_{k,\ell,m}}\Big(\theta_{k,\ell,m} - \frac{1}{\hat L_F}\nabla_\theta F^{(k,\ell,m)}_{t_{k,\ell,m}}(\theta_{k,\ell,m})\Big) \leq F^{(k,\ell,m)}_{t_{k,\ell,m}}\Big(\theta_{k,\ell,m}\Big) - \frac{1}{2 \hat L_F} \Big| \Big| \nabla_\theta F^{(k,\ell,m)}_{t_{k,\ell,m}}\Big(\theta_{k,\ell,m}\Big) \Big| \Big| ^2,
    \label{ineq:F} \\
    %
    G^{(k,\ell,m)}_{t_{k,\ell,m}}\Big(\eta_{k,\ell,m} - \frac{1}{\hat L_G}\nabla_\eta G^{(k,\ell,m)}_{t_{k,\ell,m}}(\eta_{k,\ell,m})\Big) \leq G^{(k,\ell,m)}_{t_{k,\ell,m}}\Big(\eta_{k,\ell,m}\Big) - \frac{1}{2 \hat L_G} \Big| \Big|  \nabla_\eta G^{(k,\ell,m)}_{t_{k,\ell,m}}\Big(\eta_{k,\ell,m}\Big) \Big| \Big|^2.
    \label{ineq:G}
\end{gather}
%
The inequalities above are obeyed if $\hat L_F = L_F$ and $\hat L_G = L_G$. Therefore, if either of the two inequalities above are violated, then the corresponding Lipschitz constant estimate ($\hat L_F$ or $\hat L_G$) is doubled. \citet{Schmidt:2017} also do not check this inequality if either $||\nabla_\theta F^{(k,\ell,m)}_{t_{k,\ell,m}}(\theta_{k,\ell,m})|| < 10^{-8}$ or $||\nabla_\eta G^{(k,\ell,m)}_{t_{k,\ell,m}}(\eta_{k,\ell,m})|| < 10^{-8}$ due to numerical instability. 

In addition, when $\phi$ is close to a local maximum of the likelihood, a larger step size (i.e. a smaller Lipschitz constant) may be used while maintaining numerical stability. Therefore, after each parameter update, the Lipschitz constant estimates are decreased by a small amount:
%
\begin{equation}
    \hat L_F \leftarrow 2^{-1/T} ~ \hat L_F, \qquad \hat L_G \leftarrow 2^{-1/T} ~ \hat L_G
\end{equation}
%
Adaptively updating $L_F$ and $L_G$ allows the step size of the optimization algorithm to adapt to the smoothness of the objective function.

%\subsection{Warm Starting}

%If the data set is very large, it can be computational burdensome to initialize the first E-step of this algorithm. Therefore, the problem can be treated as an online learning algorithm for the first pass of the data.

%\subsection{Mini-batch sizes}

%Select a mini-batch depending upon the value of the largest diagonal of $\widehat \Gamma$ since the Markov chain is expected to stay in its current state no longer than $\max_i 1/(1-\Gamma_{ii})$ iterations. This is because we would intuitively like to actually update the chain every partial E-step.

\subsection{Different Lipschitz constants for each hidden state}
\label{subsec:diff_Ls}

The optimization problem within the M-step of the Baum Welch algorithm can be written as follows:

\begin{equation} 
    \theta_{k+1} = \argmin_{\theta} - \sum_{t=1}^T \sum_{i=1}^N \gamma^{(i)}_t(\phi_{k}) \log f^{(i)}(y_t;\theta^{(i)})
\end{equation}

\begin{equation}
    \eta^{(\cdot,\cdot)}_{k+1} = \argmin_{\eta^{(\cdot,\cdot)}} - \sum_{t=2}^T \sum_{i=1}^N \sum_{j=1}^N \xi^{(i,j)}_t(\phi_{k}) \log \Gamma^{(i,j)}(\eta)
\end{equation}

\begin{equation}
    \eta^{(\cdot)}_{k+1} = \argmin_{\eta^{(\cdot)}} - \sum_{i=1}^N \gamma^{(i)}_t(\phi_{k}) \log \delta^{(i)}(\eta)
\end{equation}

Recall that we denote $\eta^{(\cdot)} = \{\eta^{(i)}\}_{i=1}^N$, 
$\eta^{(i,\cdot)} = \big\{\eta^{(i,j)}\big\}_{j=1}^N$, and $\eta^{(\cdot,\cdot)} = \big\{\eta^{(i,j)}\big\}_{i,j=1}^N$. Note that $\delta^{(i)}$ depends only on $\eta^{(\cdot)}$ for $i = 1,\ldots,N$ and $\Gamma^{(i,j)}$ depends only on $\eta^{(i,\cdot)}$ for $j = 1,\ldots,N$. We can then rewrite the three optimization problems above as $2N + 1$ individual optimization problems:

\begin{equation} 
    \theta^{(i)}_{k+1} = \argmin_{\theta^{(i)}} - \sum_{t=1}^T \gamma^{(i)}_t(\phi_{k}) \log f^{(i)}(y_t;\theta^{(i)})
\end{equation}

\begin{equation}
    \eta^{(i,\cdot)}_{k+1} = \argmin_{\eta^{(i,\cdot)}} - \sum_{t=2}^T \sum_{j=1}^N \xi^{(i,j)}_t(\phi_{k}) \log \Gamma^{(i,j)}(\eta^{(i,\cdot)})
\end{equation}

\begin{equation}
    \eta^{(\cdot)}_{k+1} = \argmin_{\eta^{(\cdot)}} - \sum_{i=1}^N \gamma^{(i)}_t(\phi_{k}) \log \delta^{(i)}(\eta^{(\cdot)}).
\end{equation}

Since there are $2N+1$ separate optimization problems within the M-step of algorithm (\ref{alg:EM-SO}), we can define $2N+1$ separate step sizes for each: $\big\{\lambda_F^{(i)}\big\}_{i=1}^N$, $\big\{\lambda_G^{(i,\cdot)}\big\}_{i=1}^N$, and $\lambda_G^{(\cdot)}$. Each of these step sizes in turn can depend upon separate Lipschitz constants, $\big\{L_F^{(i)}\big\}_{i=1}^N$, $\big\{L_G^{(i,\cdot)}\big\}_{i=1}^N$, and $L_G^{(\cdot)}$. The procedure described in Section 4.1 can then be used to adapt $L_F^{(i)}$, $L_G^{(i,\cdot)}$, and $L_G^{(\cdot)}$ dynamically over the course of the algorithm.

\subsection{Adaptive Step Size for Fixed Lipschitz Constant}
\label{subsec:L_divider}

Under certain regularity conditions, \citet{Defazio:2014} prove that SAGA converges using step sizes of $1/(3L_F)$ and $1/(3L_G)$. We therefore initialize step sizes of $\lambda_G = 1/(3 \hat L_G)$ and $\lambda_F = 1/(3 \hat L_F)$ for all experiments and algorithms. However, algorithm (\ref{alg:P-EM-SO}) combines the E- and the M-step of the Baum-Welch algorithm, so it may be that $1/(3 \hat L_F)$ and $1/(3 \hat L_G)$ are too large, even if $\hat L_F$ and $\hat L_G$ are good estimates of $L_F$ and $L_G$. As such, if the log-likelihood does not decrease after iteration $k$ and attempt $\ell$ through the M-step of algorithm (\ref{alg:P-EM-SO}), we double the Lipschitz constants for attempt $\ell+1$. For example, if the step sizes are $\lambda_F = 1/(3 \hat L_F)$ and $\lambda_G = 1/(3 \hat L_G)$ for attempt $\ell$ of algorithm (\ref{alg:P-EM-SO}), and attempt $\ell$ results in an increase of the log-likelihood, we define new step-sizes $\lambda_F \leftarrow 1/(6 \hat L_F)$ and $\lambda_G \leftarrow 1/(6 \hat L_F)$ for attempt $\ell+1$.

\subsection{Sampling for SAGA and SVRG without Replacement}
\label{subsec:wo_replacement}

Finally, we sample each random index $t_{k,\ell,m}$ \textit{without} replacement for the M-step of algorithms (\ref{alg:EM-SO}) and (\ref{alg:P-EM-SO}). Sampling without replacement for SGD is often easier to implement and performs better than sampling with replacement \citep{Gurbuzbalaban:2015}. \citet{Ohad:2016} gives several convergence results for SVRG when indices are sampled without replacement.