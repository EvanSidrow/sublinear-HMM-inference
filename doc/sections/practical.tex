%\section{Practical Considerations}

Algorithm (\ref{alg:EM-VRSO}) outlines a method to perform the Baum-Welch algorithm with a stochastic E and M step. This section outlines implementation details that improve its practical performance. In particular, this section outlines methods to select an appropriate step size which can drastically affect the practical performance of the algorithm.

\subsection{Line-search for step size selection}
\label{subsec:est_L}

One major drawback of stochastic optimization algorithms is that the step size can greatly affect practical performance. %\citet{Schmidt:2017} suggest using step sizes of $\lambda_F = 1/(16L_F)$ and $\lambda_G = 1/(16L_G)$ for theoretical guarantees within the SAG algorithm, where $L_F$ and $L_G$ are defined in Theorem 1. Similarly, 
\citet{Defazio:2014} suggest step sizes of $\lambda = 1/(3L)$ for SAGA, where $L$ is the Lipschitz constant defined in Theorem 1. However, the Lipschitz constants are rarely known in practice. Therefore, following \citet{Schmidt:2017}, we initialize an estimate of the Lipschitz constant, $\hat L$, and update it if the following inequality does not hold at any step of the optimization algorithm:

\begin{gather}
    F^{(k)}_{t_{m}}\Big(\bfphi_{m} - \frac{1}{\hat L}\nabla F^{(k)}_{t_{m}}(\bfphi_{m})\Big) \leq F^{(k)}_{t_{m}}\Big(\bfphi_{m}\Big) - \frac{1}{2 \hat L} \Big| \Big| \nabla F^{(k)}_{t_{m}}\Big(\bfphi_{m}\Big) \Big| \Big| ^2,
    \label{ineq:F}
\end{gather}
%
The inequality above is obeyed if $\hat L = L$, so if it is violated, then we double the Lipschitz constant estimate $\hat L$. \citet{Schmidt:2017} also do not check this inequality if $||\nabla F^{(k)}_{t_{m}}(\bfphi_{m})|| < 10^{-8}$ due to numerical instability. 

In addition, when $\bfphi$ is close to a local maximum of the likelihood, a larger step size (i.e. a smaller Lipschitz constant) may be used while maintaining numerical stability. Therefore, after each parameter update, the Lipschitz constant estimate is decreased by a small amount:
%
\begin{equation}
    \hat L \leftarrow 2^{-1/T} ~ \hat L
\end{equation}
%
Updating $\hat L$ after each parameter update allows the step size of the optimization algorithm to adapt to the smoothness of the objective function close to the optimum value.

%\subsection{Warm Starting}

%If the data set is very large, it can be computational burdensome to initialize the first E step of this algorithm. Therefore, the problem can be treated as an online learning algorithm for the first pass of the data.

%\subsection{Mini-batch sizes}

%Select a mini-batch depending upon the value of the largest diagonal of $\widehat \Gamma$ since the Markov chain is expected to stay in its current state no longer than $\max_i 1/(1-\Gamma_{ii})$ iterations. This is because we would intuitively like to actually update the chain every partial E step.

\subsection{Multiple step sizes}

The optimization problem within the M step of the Baum-Welch algorithm can be written as two separate optimization problems over $\bftheta$ and $\bfeta$ (recall that $\bfphi = \{\bftheta,\bfeta\}$). In particular, we can rewrite $F_t$ as $F^{(k)}_t(\bfphi \mid \gamma_t, \xi_t) = G^{(k)}_t(\bftheta \mid \gamma_t, \xi_t) + H^{(k)}_t(\bfeta \mid \gamma_t, \xi_t)$, where

\begin{gather}
    G^{(k)}_t(\bftheta \mid \gamma_t, \xi_t) = - \sum_{i=1}^N \gamma^{(i)}_t \log f^{(i)}(y_t;\theta^{(i)}), \enspace t = 1,\ldots,T, \\
    %
    H^{(k)}_1(\bfeta \mid \gamma_t, \xi_t) = - \sum_{i=1}^N \gamma^{(i)}_t \log \delta^{(i)}(\bfeta), \qquad H^{(k)}_t(\bfeta \mid \gamma_t, \xi_t) =  - \sum_{i=1}^N \sum_{j=1}^N \xi^{(i,j)}_t \log \Gamma^{(i,j)}(\bfeta), \enspace t \geq 2,
\end{gather}
%
\begin{equation}
    \bftheta_{k+1} = \argmin_{\bftheta} \frac{1}{T} \sum_{t=1}^T G^{(k)}_t(\bftheta \mid \gamma_t(\bfphi_k), \xi_t(\bfphi_k)), \qquad \bfeta_{k+1} = \argmin_{\bfeta} \frac{1}{T} \sum_{t=1}^T H^{(k)}_t(\bfeta \mid \gamma_t(\bfphi_k), \xi_t(\bfphi_k)).
\end{equation}
%
Since $\bftheta_{k+1}$ and $\bfeta_{k+1}$ can be updated by solving two different optimization problems, we define step sizes for each: $\lambda_{\bftheta}$, and $\lambda_{\bfeta}$. Each of these step sizes in turn depend upon separate Lipschitz constant estimates, $\lambda_{\bftheta} = 1/(3\hat L_G)$ and $\lambda_{\bfeta} = 1/(3\hat L_H)$. The line search described in Section 4.1 can then be used to update the estimates $\hat L_G$ and $\hat L_H$.

\subsection{Adaptive Step Size for Fixed Lipschitz Constant}
\label{subsec:L_divider}

Under certain regularity conditions, \citet{Defazio:2014} prove that SAGA converges using a step size of $1/(3L)$. We therefore initialize step sizes of $\lambda_{\bftheta} = 1/(3 \hat L_G)$ and $\lambda_{\bfeta} = 1/(3 \hat L_H)$ for all experiments and algorithms. However, Algorithm (\ref{alg:EM-VRSO}) with $P = \texttt{True}$ combines the E and the M step of the Baum-Welch algorithm, so it may be that $1/(3 \hat L_G)$ and $1/(3 \hat L_H)$ are too large since the objective function itself is changing. As such, if the log-likelihood does not decrease after iteration $k$ and attempt $\ell$ through the M step of Algorithm (\ref{alg:EM-VRSO}) with $P = \texttt{True}$, we double the Lipschitz constants for attempt $\ell+1$. For example, if the step sizes are $\lambda_{\bftheta} = 1/(3 \hat L_G)$ and $\lambda_{\bfeta} = 1/(3 \hat L_H)$ for attempt $\ell$, and attempt $\ell$ results in an increase of the log-likelihood, we define new step-sizes $\lambda_{\bftheta} \leftarrow 1/(6 \hat L_G)$ and $\lambda_{\bfeta} \leftarrow 1/(6 \hat L_H)$ for attempt $\ell+1$.

\subsection{Sampling for SAGA and SVRG without Replacement}
\label{subsec:wo_replacement}

Finally, we sample each random index $t_{m}$ \textit{without} replacement for the M step of algorithms (\ref{alg:VRSO-PE}). Sampling without replacement for SGD is often easier to implement and performs better than sampling with replacement \citep{Gurbuzbalaban:2015}. \citet{Ohad:2016} also gives several convergence results for SVRG when indices are sampled without replacement.